library(MASS)
library(dplyr)
library(tmle)
library(doParallel)
library(ggplot2)
library(reshape2)
# setwd('~/Desktop/CTMLE-continue/SL_CTMLE0/')
library(ctmle)
source('xgb_try.R')
n <- 1000
partial <- 5
Rep = 100
registerDoParallel(20)
name <- 'noac'
gamma <- 0.025
gnCV = FALSE
data <- read.csv(paste('data/screened_', name,  '.csv', sep = ''))
A_full <- data[,1]
# 1 to 20 are baseline
W_full <- as.matrix(data[,3:dim(data)[2]])
if(name == 'noac'){
W_full <- W_full[,-c(49,50)]
}
set.seed(1992)
confounder_ind <- order(cor(A_full, W_full))[1:40]
confounder_ind  <- confounder_ind[order(confounder_ind)]
Qbeta <- -abs(rnorm(length(confounder_ind))) * 0.38
Y_0 <- 2 + W_full[, confounder_ind ] %*% as.matrix(Qbeta) + 1 * 0
Y_1 <- 2 + W_full[, confounder_ind ] %*% as.matrix(Qbeta) + 1 * 1
Y_full <- 10 + W_full[, confounder_ind ] %*% as.matrix(Qbeta) + 1 * A_full
psi_true <- mean(Y_1 - Y_0)
psi_true
psi_naive <- mean(Y_full[A_full == 1]) - mean(Y_full[A_full == 0])
psi_naive
hist(Y_full)
N <- length(Y_full)
print(i)
ind <- sample(1:N, n, replace = FALSE)
Y <- Y_full[ind]
A <- A_full[ind]
W <- data.frame(W_full[ind, ])
W_base <- W[, 1:partial]
Y1<-Y[which(A==1)]
Y0<-Y[which(A==0)]
treated <- data.frame(cbind(Y1, W[which(A==1),confounder_ind[1:partial]]))
untreated <- data.frame(cbind(Y0, W[which(A==0),confounder_ind[1:partial]]))
#Initial Q-estimate
beta1hat<-predict(glm(Y1 ~., data = treated), newdata= W[,confounder_ind[1:partial]])
beta0hat<-predict(glm(Y0 ~., data = untreated), newdata= W[,confounder_ind[1:partial]])
Q <-matrix(c(beta0hat,beta1hat), ncol=2)
############################################################
############################################################
V = 5
folds <-by(sample(1:n, n), rep(1:V, length = n), list)
SL.library = c('SL.glmnet', 'SL.xgboost1')
gn_base_fit = ctmle::build_gn_seq(A, W, SL.library , folds = folds)
weights = gn_base_fit$details$coef
if(gnCV){
gn_base = gn_base_fit$gn_candidates
}else{
gn_base = gn_base_fit$gn_candidates_cv
}
g1W <-  bound(gn_base %*% weights, c(gamma, 1- gamma))
#----------------------------------------
#Initial g-estimate
# Naive estimator
tauhatnaive <- mean(Y1)-mean(Y0)
tauhatnaive
# MLE
tauhatimp <- mean(beta1hat)-mean(beta0hat)
tauhatimp
# IPTW
tauhatiptw <- mean(A * Y /(g1W) - (1-A)*Y/(1- g1W))
tauhatiptw
# A-ITPW
tauhatdr <- mean(((A*Y)-(A-g1W) * beta1hat)/g1W)-
mean((((1-A)*Y)+(A-g1W)*beta0hat)/(1-g1W))
tauhatdr
#!!! SE for A-IPTW
DR_SE <- sqrt(var((((A*Y)-(A-g1W) * beta1hat)/g1W)-
((((1-A)*Y)+(A-g1W)*beta0hat)/(1-g1W)))/n)
DR_ci <-  tauhatdr + DR_SE  * c(-1.96, 1.96)
# TMLE
tauhattmlemod <- tmle(Y=Y,A=A,W=data.frame(W=W),Q=Q,g1W=g1W)
tauhattmle <- tauhattmlemod$estimates$ATE$psi
################################################################
################################################################
# 1. Use C-TMLE to tune seperately
# 2. Use SL to combine
# 3. Plug in for TMLE
# First for XGB
dtrain <- xgb.DMatrix(as.matrix(sapply(W, as.numeric)), label = A)
cv <- xgb.cv(data = dtrain, nrounds = 10000, nthread = 1, nfold = 5, minchildweight = 10,
metrics = list("logloss"), early_stopping_rounds = 50,
max_depth = 4, eta = 0.1, objective = "binary:logistic")
xgb_best <- cv$best_iteration
xgbs <- create.SL.xgboost(tune = list(ntrees = xgb_best + (1:20), max_depth = c(4), shrinkage = c(0.1),
minobspernode = c(10)))
gn_xgbs = ctmle::build_gn_seq(A, W, xgbs$names , folds = folds)
ctmle_xgb_fit <- ctmleGeneral( Y = Y, A = A, W = W, Q = Q, ctmletype = 1,
gn_candidates = gn_xgbs$gn_candidates,
gn_candidates_cv = gn_xgbs$gn_candidates_cv,
folds = folds)
ctmle_xgb_index <- ctmle_xgb_fit$best_k
xgb_best_ctmle <- xgbs$names[ctmle_xgb_index]
# Glmnet
foldid <- rep(0, n)
for(i in 1:length(folds)){
foldid[folds[[i]]] = i
}
glmnet_fit <- cv.glmnet(x = as.matrix(sapply(W, as.numeric)), y = A, foldid = foldid, family = 'binomial', keep = TRUE)
gn_glmnets_cv <- glmnet_fit$fit.preval[, glmnet_fit$lambda < glmnet_fit$lambda.min]
gn_glmnets_cv <- gn_glmnets_cv[,colSums(!is.na(gn_glmnets_cv)) > 0]
lambdas <- glmnet_fit$lambda[glmnet_fit$lambda < glmnet_fit$lambda.min]
gn_glmnets <- glmnet(y = A, x = as.matrix(sapply(W, as.numeric)), lambda = lambdas)
gn_glmnets <- predict(gn_glmnets, newx = as.matrix(sapply(W, as.numeric)))
ctmle_glmnet_fit <- ctmleGeneral( Y = Y, A = A, W = W, Q = Q, ctmletype = 1,
gn_candidates = gn_glmnets,
gn_candidates_cv = gn_glmnets_cv,
folds = folds)
ctmle_glmnet_index <- ctmle_glmnet_fit$best_k
ctmle_glmnet_lambda <- glmnet_fit$lambda[glmnet_fit$lambda < glmnet_fit$lambda.min][ctmle_glmnet_fit$best_k]
SL.glmnet1 <- function(..., lambda = ctmle_glmnet_lambda){
SL.glmnet(..., lambda = lambda)
}
SL.library <- c(xgb_best_ctmle, 'SL.glmnet1')
SL_final <- SuperLearner(Y = A, X = W, SL.library = SL.library, cvControl = list(V = 5L), verbose = TRUE)
gn_SL <- predict(SL_final)$pred
######
gn_SL[gn_SL > 0.975] = 0.975
gn_SL[gn_SL < 0.025] = 0.025
tauhatiptw_c <- mean(A * Y /(gn_SL) - (1-A)*Y/(1- gn_SL))
tauhatiptw_c
# A-ITPW
tauhatdr_c <- mean(((A*Y)-(A-gn_SL) * beta1hat)/gn_SL)-
mean((((1-A)*Y)+(A-gn_SL)*beta0hat)/(1-gn_SL))
tauhatdr_c
#!!! SE for A-IPTW
DR_SE_c <- sqrt(var((((A*Y)-(A-gn_SL) * beta1hat)/gn_SL)-
((((1-A)*Y)+(A-gn_SL)*beta0hat)/(1-gn_SL)))/n)
DR_ci_c <-  tauhatdr_c + DR_SE_c  * c(-1.96, 1.96)
tauhattmlemod_c <- tmle(Y=Y,A=A,W=data.frame(W=W),Q=Q, g1W=gn_SL)
tauhattmle_c <- tauhattmlemod_c$estimates$ATE$psi
tauhats <- data.frame(Naive=tauhatnaive,
Imp=tauhatimp,
IPTW = tauhatiptw,
IPTW_c = tauhatiptw_c,
DR=tauhatdr,
DR_c = tauhatdr_c,
TMLE = tauhattmle,
TMLE_c = tauhattmle_c
)
tauhats
gn_base_fit$details
gn_base_fit$details
SL_final
covered <- function(x){(x[1] < 1) & (x[2] > 1)}
ci_len  <- function(x){(x[2] - x[1])}
ci <- data.frame(
DR = covered(DR_ci),
DR_c = covered(DR_ci_c),
TMLE = covered(tauhattmlemod$estimates$ATE$CI),
TMLE_c = covered(tauhattmlemod_c$estimates$ATE$CI)
)
ci
ci_length <- data.frame(
DR = ci_len(DR_ci),
DR_c = ci_len(DR_ci_c),
TMLE = ci_len(tauhattmlemod$estimates$ATE$CI),
TMLE_c = ci_len(tauhattmlemod_c$estimates$ATE$CI)
)
ci_length
tauhattmlemod_c$estimates$ATE$CI
tauhattmlemod$estimates$ATE$CI
DR_ci
DR_ci_c
devtools::build()
devtools::release()
build_win()
devtools::build_win()
devtools::release()
devtools::document()
devtools::document()
devtools::build_win()
devtools::document()
devtools::build()
devtools::check()
devtools::build_win()
test_check("ctmle")
devtools::test_check("ctmle")
install.packages('SuperLearner')
install.packages("SuperLearner")
devtools::check()
devtools::release()
N <- 1000
p = 3
V = 5
Wmat <- matrix(rnorm(N * p), ncol = p)
gcoef <- matrix(c(-1,-1,rep(-(3/((p)-2)),(p)-2)),ncol=1)
W <- as.data.frame(Wmat)
g <- 1/(1+exp(Wmat%*%gcoef / 3))
A <- rbinom(N, 1, prob = g)
folds <-by(sample(1:N,N), rep(1:V, length=N), list)
SL.library = c('SL.glmnet', 'SL.glm')
m <- length(SL.library)
gn_seq <- build_gn_seq(A = A, W = W, SL.library = SL.library, folds = folds)
expect_equal(dim(gn_seq$gn_candidates_cv), c(N, m))
devtools::release()devtools::submit_cran()
devtools::submit_cran()
devtools::check()
devtools::submit_cran()
N <- 1000
p = 3
V = 5
Wmat <- matrix(rnorm(N * p), ncol = p)
gcoef <- matrix(c(-1,-1,rep(-(3/((p)-2)),(p)-2)),ncol=1)
W <- as.data.frame(Wmat)
g <- 1/(1+exp(Wmat%*%gcoef / 3))
A <- rbinom(N, 1, prob = g)
folds <-by(sample(1:N,N), rep(1:V, length=N), list)
# WARNING: Do not use this test case in testthat!!
# This test case could pass test(), but not testthat(), due to the environment issue
# lasso_fit <- cv.glmnet(x = as.matrix(W), y = A, alpha = 1, nlambda = 100, nfolds = 10)
# lasso_lambdas <- lasso_fit$lambda[lasso_fit$lambda <= lasso_fit$lambda.min][1:5]
# Build template for glmnet
# SL.glmnet_new <- function(Y, X, newX, family, obsWeights, id, alpha = 1,
#                            nlambda = 100, lambda = 0,...){
#       # browser()
#       if (!is.matrix(X)) {
#             X <- model.matrix(~-1 + ., X)
#             newX <- model.matrix(~-1 + ., newX)
#       }
#       fit <- glmnet::glmnet(x = X, y = Y,
#                             lambda = lambda,
#                             family = family$family, alpha = alpha)
#       pred <- predict(fit, newx = newX, type = "response")
#       fit <- list(object = fit)
#       class(fit) <- "SL.glmnet"
#       out <- list(pred = pred, fit = fit)
#       return(out)
# }
#
# # Use a sequence of estimator to build gn sequence:
# SL.cv1lasso <- function (... , alpha = 1, lambda = lasso_lambdas[1]){
#       SL.glmnet_new(... , alpha = alpha, lambda = lambda)
# }
#
# SL.cv2lasso <- function (... , alpha = 1, lambda = lasso_lambdas[2]){
#       SL.glmnet_new(... , alpha = alpha, lambda = lambda)
# }
#
# SL.cv3lasso <- function (... , alpha = 1, lambda = lasso_lambdas[3]){
#       SL.glmnet_new(... , alpha = alpha, lambda = lambda)
# }
#
# SL.cv4lasso <- function (... , alpha = 1, lambda = lasso_lambdas[4]){
#       SL.glmnet_new(... , alpha = alpha, lambda = lambda)
# }
# SL.library = c('SL.cv1lasso', 'SL.cv2lasso', 'SL.cv3lasso', 'SL.cv4lasso', 'SL.glm')
SL.library = c('SL.glmnet', 'SL.glm')
m <- length(SL.library)
gn_seq <- build_gn_seq(A = A, W = W, SL.library = SL.library, folds = folds)
N <- 100
p = 5
Wmat <- matrix(rnorm(N * p), ncol = p)
beta1 <- 4+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]
beta0 <- 2+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]
tauW <- 2
tau <- 2
gcoef <- matrix(c(-1,-1,rep(-(3/((p)-2)),(p)-2)),ncol=1)
Wm <- as.matrix(Wmat)
g <- 1/(1+exp(Wm%*%gcoef))
A <- rbinom(N, 1, prob = g)
sigma <- 1
epsilon <-rnorm(N,0,sigma)
Y  <- beta0 + tauW*A + epsilon
#----------------------------------------------------------------
#----------------------Test for discrete CTMLE-------------------
#----------------------------------------------------------------
# With initial estimate of Q
Q <- cbind(rep(mean(Y[A == 0]), N), rep(mean(Y[A == 1]), N))
time_greedy <- system.time(
ctmle_discrete_fit1 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat), Q = Q,
preOrder = FALSE)
)
ctmle_discrete_fit2 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat),
preOrder = FALSE, detailed = TRUE)
ctmle_discrete_fit2$candidates
time_preorder <- system.time(
ctmle_discrete_fit3 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat), Q = Q,
preOrder = TRUE,
order = rev(1:p), detailed = TRUE)
)
V = 5
folds <- by(sample(1:N,N), rep(1:V, length=N), list)
ctmle_discrete_fit4 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat), Q = Q,
preOrder = TRUE, V = 5, folds = folds,
order = 1:p, detailed = TRUE)
# No user-specified order, should be a warning
expect_warning(
ctmle_discrete_fit5 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat),Q = Q,
preOrder = TRUE, V = 5, folds = folds,
detailed = TRUE)
)
N <- 1000
p = 10
Wmat <- matrix(rnorm(N * p), ncol = p)
beta1 <- 4+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
beta0 <- 2+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
tau <- 2
gcoef <- matrix(c(-1,-1,rep(0,(p)-2)),ncol=1)
Wm <- as.matrix(Wmat)
g <- 1/(1+exp(Wm%*%gcoef / 3))
# hist(g)
A <- rbinom(N, 1, prob = g)
sigma <- 1
epsilon <-rnorm(N,0,sigma)
Y  <- beta0 + tau * A + epsilon
#----------------------------------------------------------------
#----------------------Test for glmnet CTMLE---------------------
#----------------------------------------------------------------
# cgmleGlmnet must provide user-specified Q
W_tmp <- data.frame(Wm[,1:3])
treated<- W_tmp[which(A==1),]
untreated<-W_tmp[which(A==0),]
Y1<-Y[which(A==1)]
Y0<-Y[which(A==0)]
#Initial Q-estimate
beta1hat <- predict(lm(Y1~.,
data=treated),newdata=W_tmp)
beta0hat <- predict(lm(Y0~.,
data=untreated),newdata=W_tmp)
Q <- matrix(c(beta0hat,beta1hat),ncol=2)
W = Wm
glmnet_fit <- cv.glmnet(y = A, x = Wm, family = 'binomial', nlambda = 40)
lambdas <-glmnet_fit$lambda[(which(glmnet_fit$lambda==glmnet_fit$lambda.min)):length(glmnet_fit$lambda)]
ctmle_fit1 <- ctmleGlmnet(Y=Y, A=A,
W=data.frame(W=W),
Q = Q, lambdas = lambdas,
ctmletype=1, alpha=.995,
family="gaussian",
gbound=0.025,like_type="loglik" ,
fluctuation="logistic", verbose=FALSE,
detailed=FALSE, PEN=FALSE,
V=5, stopFactor=10^6)
ctmle_fit2 <- ctmleGlmnet(Y=Y, A=A,
W=data.frame(W=W),
Q = Q, lambdas = lambdas,
ctmletype=2, alpha=.995,
family="gaussian",
gbound=0.025,like_type="loglik" ,
fluctuation="logistic", verbose=FALSE,
detailed=FALSE, PEN=FALSE,
V=5, stopFactor=10^6)
gcv <- predict.cv.glmnet(glmnet_fit, newx=Wm, s="lambda.min",type="response")
gcv <- bound(gcv,c(0.025,0.975))
s_prev <- glmnet_fit$lambda[(1:which(glmnet_fit$lambda == glmnet_fit$lambda.min))]
gcvPrev <- predict.cv.glmnet(glmnet_fit,newx=Wm,s=s_prev[length(s_prev)],type="response")
gcvPrev <- bound(gcvPrev,c(0.025,0.975))
tlme_fit <- tmle(Y = Y, A = A, W = W, Q = Q, g1W = gcv)
ctmle_fit3 <- ctmleGlmnet(Y=Y, A=A,
W=W, Q = Q,
ctmletype=3, g1W = gcv, g1WPrev = gcvPrev,
alpha=.995, family="gaussian",
gbound=0.025,like_type="loglik" ,
fluctuation="logistic", verbose=FALSE,
detailed=FALSE, PEN=FALSE,
V=5, stopFactor=10^6)
tlme_fit
ctmle_fit3
ctmle_fit2
set.seed(123)
N <- 100
p = 10
Wmat <- matrix(rnorm(N * p), ncol = p)
beta1 <- 4+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
beta0 <- 2+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
tau <- 2
gcoef <- matrix(c(-1,-1,rep(0,(p)-2)),ncol=1)
Wm <- as.matrix(Wmat)
g <- 1/(1+exp(Wm%*%gcoef / 3))
# hist(g)
A <- rbinom(N, 1, prob = g)
sigma <- 1
epsilon <-rnorm(N,0,sigma)
Y  <- beta0 + tau * A + epsilon
#----------------------------------------------------------------
#----------------------Test for glmnet CTMLE---------------------
#----------------------------------------------------------------
# cgmleGlmnet must provide user-specified Q
W_tmp <- data.frame(Wm[,1:3])
treated<- W_tmp[which(A==1),]
untreated<-W_tmp[which(A==0),]
Y1<-Y[which(A==1)]
Y0<-Y[which(A==0)]
#Initial Q-estimate
beta1hat <- predict(lm(Y1~.,
data=treated),newdata=W_tmp)
beta0hat <- predict(lm(Y0~.,
data=untreated),newdata=W_tmp)
Q <- matrix(c(beta0hat,beta1hat),ncol=2)
W = Wm
glmnet_fit <- cv.glmnet(y = A, x = Wm, family = 'binomial', nlambda = 40)
lambdas <-glmnet_fit$lambda[(which(glmnet_fit$lambda==glmnet_fit$lambda.min)):length(glmnet_fit$lambda)]
ctmle_fit1 <- ctmleGlmnet(Y=Y, A=A,
W=data.frame(W=W),
Q = Q, lambdas = lambdas,
ctmletype=1, alpha=.995,
family="gaussian",
gbound=0.025,like_type="loglik" ,
fluctuation="logistic", verbose=FALSE,
detailed=FALSE, PEN=FALSE,
V=5, stopFactor=10^6)
ctmle_fit2 <- ctmleGlmnet(Y=Y, A=A,
W=data.frame(W=W),
Q = Q, lambdas = lambdas,
ctmletype=2, alpha=.995,
family="gaussian",
gbound=0.025,like_type="loglik" ,
fluctuation="logistic", verbose=FALSE,
detailed=FALSE, PEN=FALSE,
V=5, stopFactor=10^6)
gcv <- predict.cv.glmnet(glmnet_fit, newx=Wm, s="lambda.min",type="response")
gcv <- bound(gcv,c(0.025,0.975))
s_prev <- glmnet_fit$lambda[(1:which(glmnet_fit$lambda == glmnet_fit$lambda.min))]
gcvPrev <- predict.cv.glmnet(glmnet_fit,newx=Wm,s=s_prev[length(s_prev)],type="response")
gcvPrev <- bound(gcvPrev,c(0.025,0.975))
tlme_fit <- tmle(Y = Y, A = A, W = W, Q = Q, g1W = gcv)
ctmle_fit3 <- ctmleGlmnet(Y=Y, A=A,
W=W, Q = Q,
ctmletype=3, g1W = gcv, g1WPrev = gcvPrev,
alpha=.995, family="gaussian",
gbound=0.025,like_type="loglik" ,
fluctuation="logistic", verbose=FALSE,
detailed=FALSE, PEN=FALSE,
V=5, stopFactor=10^6)
tlme_fit
ctmle_fit3
ctmle_fit2
N <- 100
p = 5
Wmat <- matrix(rnorm(N * p), ncol = p)
beta1 <- 4+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]
beta0 <- 2+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]
tauW <- 2
tau <- 2
gcoef <- matrix(c(-1,-1,rep(-(3/((p)-2)),(p)-2)),ncol=1)
Wm <- as.matrix(Wmat)
g <- 1/(1+exp(Wm%*%gcoef))
A <- rbinom(N, 1, prob = g)
sigma <- 1
epsilon <-rnorm(N,0,sigma)
Y  <- beta0 + tauW*A + epsilon
#----------------------------------------------------------------
#----------------------Test for discrete CTMLE-------------------
#----------------------------------------------------------------
# With initial estimate of Q
Q <- cbind(rep(mean(Y[A == 0]), N), rep(mean(Y[A == 1]), N))
time_greedy <- system.time(
ctmle_discrete_fit1 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat), Q = Q,
preOrder = FALSE)
)
ctmle_discrete_fit2 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat),
preOrder = FALSE, detailed = TRUE)
ctmle_discrete_fit2$candidates
time_preorder <- system.time(
ctmle_discrete_fit3 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat), Q = Q,
preOrder = TRUE,
order = rev(1:p), detailed = TRUE)
)
V = 5
folds <- by(sample(1:N,N), rep(1:V, length=N), list)
ctmle_discrete_fit4 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat), Q = Q,
preOrder = TRUE, V = 5, folds = folds,
order = 1:p, detailed = TRUE)
# No user-specified order, should be a warning
expect_warning(
ctmle_discrete_fit5 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat),Q = Q,
preOrder = TRUE, V = 5, folds = folds,
detailed = TRUE)
)
# Actually used same order and cv-folds, should have same estimate
expect_equal(ctmle_discrete_fit4$est, ctmle_discrete_fit5$est)
expect_that(ctmle_discrete_fit4, is_a("ctmle"))
# Greedy takes longer time
expect_true(time_greedy[3] > time_preorder[3])
devtools::submit_cran()
devtools::check()
document()
devtools::document()
devtools::submit_cran()
devtools::document()
devtools::document()
devtools::submit_cran()
devtools::document()
devtools::document()
devtools::document()
devtools::submit_cran()
devtools::document()
devtools::submit_cran()
devtools::submit_cran()
devtools::document()
devtools::submit_cran()
document()
devtools::document()
devtools::document()
document()
devtools::document()
devtools::submit_cran()
install.packages('ctmle')
devtools::build()
install.packages('~/Desktop/ctmle_0.1.1.tar.gz', repos = NULL)
